{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "attack_cnn v3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajagopalmotivate1/NeuralDefense/blob/master/attack_cnn_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "d1IIenRzV7Gv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Attacking a CNN\n",
        "\n",
        "In this exercise we will train a CNN to distinguish between instances of handwritten `0` and instances of handwritten `1`. We will be using `keras` to do this.  \n",
        "\n",
        "Once we have a trained classifier, we will be using `cleverhans` to create adversarial examples."
      ]
    },
    {
      "metadata": {
        "id": "xCnpiYOuqe8e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vl-c8DBVzt1w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install pydot\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sQMVJUxoztwC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "K.tensorflow_backend._get_available_gpus()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WFDsAQFIztq_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras import Input\n",
        "from keras import layers\n",
        "from keras import datasets\n",
        "import numpy as np\n",
        "from keras import utils\n",
        "from keras.models import  Model\n",
        "from keras.utils import plot_model\n",
        "import keras\n",
        "import os\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
        "from sklearn.metrics import classification_report\n",
        "from decimal import Decimal\n",
        "import  matplotlib.pyplot as plt\n",
        "from scipy.misc import toimage\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KngtqQJEztke",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import plot_model\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E8CsqpAFztew",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fsOdvomUztYV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iFB0PHjZztQ-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nhoEjgYmWJ0E",
        "colab_type": "code",
        "outputId": "dd7c1f17-c67c-4a86-d6fc-dac73221f79e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install cleverhans"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cleverhans in /usr/local/lib/python3.6/dist-packages (3.0.1)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.3.7)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.6/dist-packages (from cleverhans) (0.6.0)\n",
            "Requirement already satisfied: pycodestyle in /usr/local/lib/python3.6/dist-packages (from cleverhans) (2.5.0)\n",
            "Requirement already satisfied: mnist~=0.2 in /usr/local/lib/python3.6/dist-packages (from cleverhans) (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.14.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from cleverhans) (3.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.5.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (0.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->cleverhans) (40.8.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iIH4d-w4V7G7",
        "colab_type": "code",
        "outputId": "841c9729-1c23-4fb0-c538-1e6580e51977",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import numpy as np\n",
        "import os\n",
        "with warnings.catch_warnings():\n",
        "    import keras # keras is still using some deprectade code\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "from cleverhans.utils_keras import KerasModelWrapper\n",
        "from cleverhans.attacks import BasicIterativeMethod, FastGradientMethod, CarliniWagnerL2\n",
        "%matplotlib inline \n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "EIL2ziyzV7G_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The MNIST dataset contains data for all of the digits, but for now we are only interested in 1s and 0s. Therefore we are extracting only those from the dataset. \n",
        "\n",
        "We also need to normalize the data. This means that whatever interval was previously covered by the input values will be squashed to `[0,1]`"
      ]
    },
    {
      "metadata": {
        "id": "CMKzVNfRV7HA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def exract_ones_and_zeroes( data, labels ):\n",
        "    data_zeroes = data[ np.argwhere( labels == 0 ).reshape( -1 ) ][ :9900 ]\n",
        "    print( data_zeroes.shape )\n",
        "    data_ones = data[ np.argwhere( labels == 1 ).reshape( -1 ) ][ :2000 ]\n",
        "    x = np.vstack( (data_zeroes, data_ones) )\n",
        "\n",
        "    # normalize the data\n",
        "    x = x / 255.\n",
        "\n",
        "    labels_zeroes = np.zeros( data_zeroes.shape[ 0 ] )\n",
        "    labels_ones = np.ones( data_ones.shape[ 0 ] )\n",
        "    y = np.append( labels_zeroes, labels_ones )\n",
        "\n",
        "    return x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y3nYU03lV7HD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load the actual data and use our preprocessing function from earlier."
      ]
    },
    {
      "metadata": {
        "id": "uWwost07V7HH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train[:20000]\n",
        "y_train = y_train[:20000]\n",
        "\n",
        "# extract ones and zeroes\n",
        "#x_train, y_train = exract_ones_and_zeroes( x_train, y_train )\n",
        "#x_test, y_test = exract_ones_and_zeroes( x_test, y_test )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "APCk9NzFV7HL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Keras expects the image to have a color channel. We need to add another dimension to our image to represent\n",
        "that color channel."
      ]
    },
    {
      "metadata": {
        "id": "nwJNnnMBV7HL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# we need to bring the data in to a format that our cnn likes\n",
        "y_train = keras.utils.to_categorical( y_train, 10 )\n",
        "y_test = keras.utils.to_categorical( y_test, 10 )\n",
        "\n",
        "if keras.backend.image_data_format( ) == 'channels_first':\n",
        "    x_train = x_train.reshape( x_train.shape[ 0 ], 1, x_train.shape[ 1 ], x_train.shape[ 2 ] )\n",
        "    x_test = x_test.reshape( x_test.shape[ 0 ], 1, x_train.shape[ 1 ], x_train.shape[ 2 ] )\n",
        "    input_shape = (1, x_train.shape[ 1 ], x_train.shape[ 2 ])\n",
        "else:\n",
        "    x_train = x_train.reshape( x_train.shape[ 0 ], x_train.shape[ 1 ], x_train.shape[ 2 ], 1 )\n",
        "    x_test = x_test.reshape( x_test.shape[ 0 ], x_train.shape[ 1 ], x_train.shape[ 2 ], 1 )\n",
        "    input_shape = (x_train.shape[ 1 ], x_train.shape[ 2 ], 1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T_e_aMgDV7HQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We need to make sure that `cleverhans` has access to our model graph. To do this we make sure that `keras` uses the same `tensorflow` session that `cleverhans` will be using. "
      ]
    },
    {
      "metadata": {
        "id": "flvawc_hV7HQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# need to some setup so everything gets excecuted in the same tensorflow session\n",
        "session = tf.Session( )\n",
        "keras.backend.set_session( session )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d64xNkKdV7HX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We are using a very simple CNN. For our two output classes this is probably overkill. This network can be used to distinguish between all 10 classes with very high accuracy."
      ]
    },
    {
      "metadata": {
        "id": "zhL7B3vYuvTs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define the classifier\n",
        "clf = keras.Sequential( )\n",
        "clf.add( Conv2D( 32, kernel_size=(3, 3), activation='relu', input_shape=input_shape ) )\n",
        "clf.add( Conv2D( 64, (3, 3), activation='relu' ) )\n",
        "clf.add( MaxPooling2D( pool_size=(2, 2) ) )\n",
        "clf.add( Dropout( 0.25 ) )\n",
        "clf.add( Flatten( ) )\n",
        "clf.add( Dense( 128, activation='relu' ) )\n",
        "clf.add( Dropout( 0.5 ) )\n",
        "clf.add( Dense( 10, activation='softmax' ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d6XBrFAex5lZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "graDJRRnzl0s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g5IYz16Mzlvf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e-DvdnnfzlmJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5yXtLUQCzlf6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#Input parameters are depthofnetwork, generalization capacity , \n",
        "\n",
        "def createANetwork(ExpNo, noofCNNlayers, noofDenselayers, noofCNNFilters, noofDensenodes  ,\n",
        "                  networkwidthTamperRate, stride, maxpool, noofPARALLELbranches , kernalsize):\n",
        "    myinputShape = (32, 32, 3)\n",
        "    myinputTensor = Input(shape=myinputShape, name='1')\n",
        "    x = myinputTensor\n",
        "    layerno = 1\n",
        "    isskipaddingMaxPool = True\n",
        "    \n",
        "    for i in range(noofCNNlayers):\n",
        "        x = layers.Conv2D(noofCNNFilters, kernel_size=(kernalsize,kernalsize), strides=(stride,stride), activation='relu', name='CNNlayer'+str(layerno)) (x)\n",
        "        print( str(layerno) + ' Conv2D  Filters=' + str(noofCNNFilters) + '.    kernel size=(' + str(kernalsize) + ' , ' + str(kernalsize) + ' )'  + ' . stride=' + str(stride) + '     Relu')\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        layerno = layerno +1\n",
        "        if(layerno > 3):\n",
        "            maxpool = 1\n",
        "        if(layerno > 1):\n",
        "            stride = 1\n",
        "        if (isskipaddingMaxPool == False):\n",
        "            x = layers.MaxPooling2D(pool_size=(maxpool, maxpool), name='MaxPool'+str(layerno)) (x)\n",
        "            print( str(layerno) + ' MaxPool  . Poolsize=' + str(maxpool) )\n",
        "            layerno = layerno +1\n",
        "            x = layers.Dropout(0.2) (x)\n",
        "            print( '  Dropout 0.2' )\n",
        "            isskipaddingMaxPool = True\n",
        "            noofCNNFilters = round( noofCNNFilters * networkwidthTamperRate )\n",
        "            if(noofCNNFilters>512):\n",
        "                noofCNNFilters = 512\n",
        "        else:\n",
        "            isskipaddingMaxPool = False\n",
        "\n",
        "\n",
        "    x = layers.Flatten(name='Flatten' + str(layerno) ) (x)\n",
        "    print(str(layerno) + ' Flatten  ' )\n",
        "\n",
        "    layerno = layerno + 1\n",
        "\n",
        "    for i in range(noofDenselayers):\n",
        "        x = layers.Dense(noofDensenodes, activation='relu', name='Dense'+ str(layerno) )(x)\n",
        "        print( str(layerno) + ' Dense  ' + str(noofDensenodes) )\n",
        "        layerno = layerno +1\n",
        "        noofDensenodes = round(noofDensenodes/2)\n",
        "\n",
        "    myoutputTensor = layers.Dense(10, activation='softmax', name='DenseMultiClassSoftmaxLayer') (x)\n",
        "\n",
        "    mymodel = Model(myinputTensor, myoutputTensor)\n",
        "\n",
        "    \n",
        "    plot_model(mymodel, show_shapes=False, show_layer_names=True, to_file='achildmodel.png')\n",
        "    print(mymodel.summary())\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "  #  plot_model(mymodel, show_shapes=True, to_file='models'+str(ExpNo) + '.png')\n",
        "   # plot_model(mymodel, show_shapes=False, to_file='m'+str(ExpNo) + '.png')\n",
        "\n",
        "\n",
        "    return mymodel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KDpS65w5zq9O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mncWAB0qzq3j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "urzq5VGqzqxd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gQFDs9lszlZ5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U7d-auOuzlSK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_OAkSntwzOwf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_callbacks(expno):\n",
        "   # tensorboard_callback = TensorBoard(log_dir=os.path.join(os.getcwd(), \"log\", \"am18d301_Exp1\" + str(expno) ), histogram_freq=1, batch_size=32,   write_graph=False, write_grads=False)\n",
        "   # checkpoint_callback = ModelCheckpoint(filepath=\"./model-weights.{epoch:02d}.hdf5\", monitor='val_acc', verbose=0, save_best_only=True)\n",
        "    earlystop = EarlyStopping(monitor='val_acc', min_delta=0.0001, patience=1, verbose=1, mode='auto')\n",
        "    return [ earlystop]\n",
        "\n",
        "\n",
        "\n",
        "def print_model_metrics(model, xtest, ytest ):\n",
        "    loss, accuracy = model.evaluate(x=xtest, y=ytest)\n",
        "    print(\"\\n model test loss is \"+str(loss)+\" accuracy is \"+str(accuracy))\n",
        "\n",
        "    y_softmax = model.predict(xtest)  # this is an n x class matrix of probabilities\n",
        "    y_hat = y_softmax.argmax(axis=-1)  # this will be the class number.\n",
        "    test_y = ytest.argmax(axis=-1)  # our test data is also categorical\n",
        "    print(classification_report(test_y, y_hat))\n",
        "    return [loss, accuracy]\n",
        "\n",
        "\n",
        "def plot_imgs(X):\n",
        "    plt.figure(1)\n",
        "    k = 0\n",
        "    for i in range(0,4):\n",
        "        for j in range(0,4):\n",
        "            plt.subplot2grid((4,4),(i,j))\n",
        "            plt.imshow(toimage(X[k]))\n",
        "            k = k+1\n",
        "    # show the plot\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def convertprecision(alongfloat):\n",
        "    alongfloat1 = Decimal(alongfloat * 100)\n",
        "    alongfloat2 = round(alongfloat1, 2)\n",
        "    myformatedfloat = float(alongfloat2)\n",
        "    return myformatedfloat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f-PoAX8ezOsm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bFiTKbrwzOoi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def runaexpeirment(ExpName, anetworkmodel):\n",
        "\n",
        "    mymodel = anetworkmodel\n",
        "\n",
        "    (xtrain1, ytrain1), (xtest, ytest) = datasets.cifar10.load_data()\n",
        "    \n",
        "    plot_imgs(xtrain1[:16])\n",
        "\n",
        "    xtrain  = xtrain1[:42000, :]\n",
        "    ytrain = ytrain1[:42000, :]\n",
        "\n",
        "    xval = xtrain1[42000:, :]\n",
        "    yval = ytrain1[42000:, :]\n",
        "\n",
        "    datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    )\n",
        "    datagen.fit(xtrain)\n",
        "    \n",
        "\n",
        "    print( 'Shape of CIFAR Training Set Inputs: ' + str(xtrain.shape) )\n",
        "    print( 'Shape of CIFAR Training Set Labels: ' + str(ytrain.shape) )\n",
        "    print( 'Shape of CIFAR Test Set Inputs: ' + str(xtest.shape) )\n",
        "    print( 'Shape of CIFAR Validation Set Inputs: ' + str(xval.shape) )\n",
        "\n",
        "\n",
        "    xtrain = xtrain.astype('float16') * 1/255\n",
        "    xtest = xtest.astype('float16') * 1/255\n",
        "    xval = xval.astype('float16') * 1/255\n",
        "\n",
        "    trainSetSize = len(xtrain)\n",
        "    testSetSize = len(xtest)\n",
        "    valSetSize = len(xval)\n",
        "\n",
        "    xtrain = xtrain.reshape((trainSetSize, 32, 32, 3))\n",
        "    xtest = xtest.reshape((testSetSize, 32, 32, 3))\n",
        "    xval = xval.reshape((valSetSize,32, 32, 3))\n",
        "\n",
        "    ytrain = utils.to_categorical(ytrain)\n",
        "    ytest = utils.to_categorical(ytest)\n",
        "    yval = utils.to_categorical(yval)\n",
        "\n",
        "    print('After preprocessing.. normalize to 1, OHE, reshaping')\n",
        "    print( 'Shape of CIFAR Training Set Inputs: ' + str(xtrain.shape) )\n",
        "    print( 'Shape of CIFAR Training Set Labels: ' + str(ytrain.shape) )\n",
        "    print( 'Shape of CIFAR Test Set Inputs: ' + str(xtest.shape) )\n",
        "\n",
        "\n",
        "    mymodel.compile(optimizer=keras.optimizers.RMSprop(), loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "\n",
        "    mycallbacksfunction = create_callbacks(ExpName)\n",
        "\n",
        "   # history = mymodel.fit(xtrain, ytrain, epochs=2, batch_size=128,\n",
        "                         # validation_data=(xval,yval),\n",
        "                         # verbose=1, \n",
        "                         # callbacks=mycallbacksfunction\n",
        "                         # )\n",
        "\n",
        "    mybatchsize = 128\n",
        "    history = mymodel.fit_generator( datagen.flow(xtrain, ytrain, batch_size=mybatchsize),\n",
        "                    steps_per_epoch=xtrain.shape[0] / mybatchsize, \n",
        "                    epochs=1,\n",
        "                    verbose=1,\n",
        "                    validation_data=(xval,yval)\n",
        "                      )\n",
        "\n",
        "    #save to disk\n",
        "    model_json = mymodel.to_json()\n",
        "    with open('model' + str(ExpName) + 's.json', 'w') as json_file:\n",
        "        json_file.write(model_json)\n",
        "    mymodel.save_weights('model'  + str(ExpName) + 's.h5') \n",
        "\n",
        "    myTESTloss, myTESTaccuracy = print_model_metrics( mymodel, xtest, ytest )\n",
        "    myVALloss, myVALaccuracy = print_model_metrics( mymodel, xval, yval )\n",
        "    myTRAINloss, myTRAINaccuracy = print_model_metrics( mymodel, xtrain, ytrain)\n",
        "\n",
        "    myTESTaccuracy = convertprecision(myTESTaccuracy)\n",
        "    myVALaccuracy = convertprecision(myVALaccuracy)\n",
        "    myTRAINaccuracy = convertprecision(myTRAINaccuracy)\n",
        "    \n",
        "\n",
        "    print(' \\n RESULTS')\n",
        "    print('TRAINING accuracy = ' + str(myTRAINaccuracy ))\n",
        "    print('VAL accuracy = ' + str(myVALaccuracy))\n",
        "    print('TEST accuracy = ' + str(myTESTaccuracy))\n",
        "    \n",
        "    \n",
        "\n",
        "    return myTRAINaccuracy, myVALaccuracy, myTESTaccuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bcCoshNgzOif",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fZmrAs46zOeh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RGwoYr-Wy0K-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ExpName = 2000\n",
        "islistcreated = False\n",
        "ListofNetworks = list()\n",
        "nooffiltersstarting =  32\n",
        "networkwidthTamperRate = 2\n",
        "noofDenselayers = 0\n",
        "noofDensenodes = 64 \n",
        "stride = 1\n",
        "maxpool = 2\n",
        "noofPARALLELbranches = 1\n",
        "noofCNNlayers = 6\n",
        "kernalsize = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SGuNRqzHy0u7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for iterate in range( 3, 6, 1):\n",
        "  \n",
        "    noofCNNlayers = iterate \n",
        "  \n",
        "    ExpName = ExpName + 1\n",
        "    generatedNetwork =  createANetwork(ExpName, noofCNNlayers,noofDenselayers, nooffiltersstarting, noofDensenodes  ,networkwidthTamperRate, stride, maxpool,  noofPARALLELbranches, kernalsize )\n",
        "    aTRAINaccuracy, aVALaccuracy, aTESTaccuracy = runaexpeirment(ExpName, generatedNetwork )\n",
        "\n",
        "    atuple = tuple((ExpName, aTRAINaccuracy, aVALaccuracy, aTESTaccuracy ,  noofCNNlayers,noofDenselayers,  nooffiltersstarting, noofDensenodes  ,networkwidthTamperRate  , stride, maxpool, noofPARALLELbranches , kernalsize, generatedNetwork))\n",
        "\n",
        "    ListofNetworks.append(atuple)\n",
        "\n",
        "    print(\" ADDED\")\n",
        "    print(atuple)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OHerkGxly1Aq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YmhlhIKvy0E6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NcMLaxIvyz9U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GMjW64ADV7HY",
        "colab_type": "code",
        "outputId": "37963ac6-4329-45ba-9761-87a108375522",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "clf.compile( loss=keras.losses.categorical_crossentropy,\n",
        "             optimizer='adam',\n",
        "             metrics=[ 'accuracy' ] )\n",
        "\n",
        "clf.fit( x_train, y_train,\n",
        "         epochs=2,\n",
        "         verbose=1 )\n",
        "#clf.summary( )\n",
        "score = clf.evaluate( x_test, y_test, verbose=0 )\n",
        "print( 'Test loss:', score[ 0 ] )\n",
        "print( 'Test accuracy:', score[ 1 ] )\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/2\n",
            "20000/20000 [==============================] - 64s 3ms/step - loss: 11.1107 - acc: 0.3068\n",
            "Epoch 2/2\n",
            "20000/20000 [==============================] - 63s 3ms/step - loss: 7.5729 - acc: 0.5276\n",
            "Test loss: 6.539933492279053\n",
            "Test accuracy: 0.5928\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VszDZ1p6V7Hc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's get to the actual attack magic. First we are picking a sample that we want to perturbate. After selecting the sample, we will use the FGSM attack and the Carlini & Wagner L2 attack to perturbate it into an adversarial example."
      ]
    },
    {
      "metadata": {
        "id": "YrbyOs_3V7He",
        "colab_type": "code",
        "outputId": "9b6adab2-0d1e-4013-e748-1f5313eb4ddd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770
        }
      },
      "cell_type": "code",
      "source": [
        "#chose a sample to pertubate\n",
        "sample_ind = 93\n",
        "\n",
        "# picking a test sample\n",
        "sample = x_test[ sample_ind, : ]\n",
        "\n",
        "\n",
        "# plot the first instance in the traning set\n",
        "plt.imshow( sample.reshape( 28, 28 ), cmap=\"gray_r\" )\n",
        "plt.axis( 'off' )\n",
        "plt.show( )\n",
        "\n",
        "# constructing adversarial examples\n",
        "print( 'class prediction for the test samples:',\n",
        "       clf.predict( sample.reshape( (1, sample.shape[ 0 ], sample.shape[ 1 ], sample.shape[ 2 ]) ) ) )\n",
        "\n",
        "prediction1 = clf.predict( sample.reshape( (1, sample.shape[ 0 ], sample.shape[ 1 ], sample.shape[ 2 ]) ) )\n",
        "\n",
        "print ( np.round(prediction1 , 2 ) )\n",
        "\n",
        "print ( np.round(prediction1) )\n",
        "\n",
        "\n",
        "# setup the attack\n",
        "wrapper = KerasModelWrapper( clf )\n",
        "fgm = FastGradientMethod( wrapper, sess=session )\n",
        "eps = 8 # allowed maximum modification\n",
        "\n",
        "# excetute the attack\n",
        "with warnings.catch_warnings():\n",
        "    modified_sample = fgm.generate_np( sample.reshape( (1, sample.shape[ 0 ], sample.shape[ 1 ], sample.shape[ 2 ]) ),\n",
        "                                   **{ 'eps': eps } )\n",
        "\n",
        "print( 'class prediction for the modified test samples:',\n",
        "       clf.predict( modified_sample.reshape( (1, sample.shape[ 0 ], sample.shape[ 1 ], sample.shape[ 2 ]) ) ) )\n",
        "\n",
        "predictiononmodifiedsample = clf.predict( modified_sample.reshape( (1, sample.shape[ 0 ], sample.shape[ 1 ], sample.shape[ 2 ]) ) )\n",
        "\n",
        "\n",
        "print ( np.round(predictiononmodifiedsample , 2 ) )\n",
        "\n",
        "print ( np.round(predictiononmodifiedsample) )\n",
        "\n",
        "plt.imshow( modified_sample.reshape( 28, 28 ), cmap=\"gray_r\" )\n",
        "plt.axis( 'off' )\n",
        "plt.show( )\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO 2019-03-11 16:26:06,953 cleverhans] Constructing new graph for attack FastGradientMethod\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "class prediction for the test samples: [[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/cleverhans/attacks/__init__.py:283: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/cleverhans/compat.py:124: calling softmax_cross_entropy_with_logits_v2_helper (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "dim is deprecated, use axis instead\n",
            "class prediction for the modified test samples: [[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "hoJerGCkScH5",
        "colab_type": "code",
        "outputId": "fa343628-7d79-4103-ea77-360052b4c32f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# let's try a stronger attack\n",
        "with warnings.catch_warnings():\n",
        "    cw_l2 = CarliniWagnerL2( wrapper, sess=session )\n",
        "    modified_sample = cw_l2.generate_np( sample.reshape( (1, sample.shape[ 0 ], sample.shape[ 1 ], sample.shape[ 2 ]) ) )\n",
        "\n",
        "print( 'class prediction for the cw modified test samples:',\n",
        "       clf.predict( modified_sample.reshape( (1, sample.shape[ 0 ], sample.shape[ 1 ], sample.shape[ 2 ]) ) ) )\n",
        "plt.imshow( modified_sample.reshape( 28, 28 ), cmap=\"gray_r\" )\n",
        "plt.axis( 'off' )\n",
        "plt.show( )\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO 2019-03-11 16:26:07,461 cleverhans] Constructing new graph for attack CarliniWagnerL2\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/cleverhans/attacks/__init__.py:1201: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, use\n",
            "    tf.py_function, which takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "class prediction for the cw modified test samples: [[0.0233332  0.02440954 0.02126921 0.7111196  0.03028556 0.04173207\n",
            "  0.00928346 0.05097632 0.07453768 0.0130533 ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAA5JJREFUeJzt3cFqq1AYRtFa8v6vbKcdJLWgnqPu\ntaZ30HDp5od+aJZ1Xb+AZ/ue/QGA8wkdAoQOAUKHAKFDwGvQz/GnfTjf8ukfXHQIEDoECB0ChA4B\nQocAoUOA0CFA6BAgdAgQOgQIHQKEDgFChwChQ4DQIUDoECB0CBA6BAgdAoQOAUKHAKFDgNAhQOgQ\nIHQIEDoECB0ChA4BQocAoUOA0CFA6BAgdAgQOgQIHQKEDgFChwChQ8Br9gcoW5Zl9keYYl3X2R8h\nx0WHAKFDgNAhQOgQIHQIEDoECB0C7Ognqu7kW7b+X+zsx3PRIUDoECB0CBA6BAgdAoQOAeY1Lsf8\ndjwXHQKEDgFChwChQ4DQIUDoECB0CBA6BAgdAoQOAUKHAKFDgNAhQOgQIHQI8Dz6ibaem/Y6aEZx\n0SFA6BAgdAgQOgQIHQKEDgFChwA7+kR7309uh+e/XHQIEDoECB0ChA4BQocAoUOA0CHAjn5hdnKO\n4qJDgNAhQOgQIHQIEDoECB0ChA4BQocAoUOA0CFA6BAgdAgQOgQIHQKEDgFChwChQ4DQIUDoECB0\nCBA6BAgdApa9X937T0N+SI3XQb836Hf6ij7+QrjoECB0CBA6BAgdAoQOAUKHAKFDgK9NvrG/9mIb\nO7+56BAgdAgQOgQIHQKEDgFChwChQ4Ad/aHOfibbTn8vLjoECB0ChA4BQocAoUOA0CFA6BAgdAgQ\nOgQIHQKEDgFChwChQ4DQIcBjqrzlMdRncdEhQOgQIHQIEDoECB0ChA4BQocAO/pEW1v1ma9stpO3\nuOgQIHQIEDoECB0ChA4BQocAoUOAHf1Ee7dqW/d7Z38l9BO56BAgdAgQOgQIHQKEDgFChwDz2g7m\nL+7CRYcAoUOA0CFA6BAgdAgQOgQIHQLs6FyOx1CP56JDgNAhQOgQIHQIEDoECB0ChA4BdnSGs5OP\n56JDgNAhQOgQIHQIEDoECB0ChA4BdvQd9u7Bd34vvC38Xlx0CBA6BAgdAoQOAUKHAKFDgNAhwI4+\nkS2aUVx0CBA6BAgdAoQOAUKHAKFDgNAhQOgQIHQIEDoECB0ChA4BQocAoUOA0CFA6BAgdAgQOgQI\nHQKEDgFChwChQ8Co1z3f9/uB4QFcdAgQOgQIHQKEDgFChwChQ4DQIUDoECB0CBA6BAgdAoQOAUKH\nAKFDgNAhQOgQIHQIEDoECB0ChA4BQocAoUOA0CHgB/ZYNxS23paUAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "HZ623cz3qhAx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}